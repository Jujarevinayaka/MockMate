âœ¦ Here's a detailed, step-by-step explanation of the functionality of each file in the project:       


  app.py
  This is the main Flask application that serves as the backend for the MockMate Gemini CLI interface.
   * Initialization (`GeminiCLIApp.__init__`): Sets up the Flask app, initializes gemini_process and gemini_window to None, defines the      
     OUTPUT_FILE path (gemini_output.txt), and registers the routes.
   * Route Registration (`_register_routes`): Maps URL paths to Python functions. Specifically, it maps / to index (for serving the main HTML
     page) and /send_prompt (for handling user prompts) to send_prompt.
   * Gemini Window Discovery (`find_gemini_window`): Uses pywinauto to search for an existing command prompt window with "gemini" in its     
     title and "ConsoleWindowClass" as its class name. This is crucial for connecting to the running Gemini CLI.
   * Gemini Launch (`launch_gemini`):
       * First, it attempts to find an already running Gemini window. If found, it focuses on it and returns True.
       * If not found, it deletes any existing gemini_output.txt file.
       * It then launches launch_gemini.bat in a new console window using subprocess.Popen.
       * It waits for up to 15 seconds, repeatedly trying to find and focus on the newly launched Gemini window.
       * Returns True if the window is found and focused, False otherwise.
   * Sending Prompts to Gemini (`send_prompt_to_gemini`):
       * Checks if a Gemini window is connected. If not, it attempts to relaunch.
       * Sets focus to the Gemini window.
       * Uses pywinauto.type_keys to type the user's prompt into the Gemini CLI and then presses Enter.
       * Handles potential errors, such as losing connection to the Gemini window.
   * Reading Latest Output (`read_latest_output`):
       * Reads the content of gemini_output.txt.
       * Compares the current content length with the previously read length (self.prev_len) to identify and return only the new output since
         the last read. This is used for streaming-like updates.
   * Index Route (`index`): Renders the index.html template, serving the main web interface to the user.
   * Send Prompt Route (`send_prompt`):
       * Receives a JSON payload containing the user's prompt.
       * Constructs a special instruction string that tells Gemini to write its response into gemini_output.txt. This is critical for        
         capturing Gemini's output.
       * Deletes gemini_output.txt before sending a new prompt to ensure a clean slate for the new response.
       * Calls send_prompt_to_gemini to send the combined instruction and user prompt to the Gemini CLI.
       * Enters a loop that waits for gemini_output.txt to be created and for new content to appear, with a timeout of 30 seconds and an idle
         threshold of 10 seconds (if no new output is received for this duration, it assumes the response is complete).
       * Reads the final content from gemini_output.txt and sends it back to the frontend as a JSON response.
   * Running the Application (`run`):
       * Calls launch_gemini to ensure the Gemini CLI is running.
       * If Gemini launches successfully, it starts the Flask development server on http://127.0.0.1:5000/.


  gemini_output.txt
  This file serves as a temporary communication channel between the Flask backend and the Gemini CLI.
   * Purpose: The app.py script instructs the Gemini CLI (via the instruction prefix) to write its responses into this file.
   * Functionality: It acts as a buffer where Gemini's output is captured, allowing the Flask application to read and display it on the web
     interface. It's cleared before each new prompt to ensure only the latest response is captured.


  web/templates/index.html
  This is the main HTML file that defines the structure of the web-based user interface.
   * Structure: It sets up a basic web page with a title, includes Tailwind CSS for styling, and links to style.css and script.js.
   * User Interface:
       * Displays a "MockMate" heading and a subtitle.
       * Contains a div with id="chat-container" where chat messages (user prompts and Gemini responses) are dynamically appended.
       * Includes a form with id="prompt-form" containing an input field (id="prompt-input") for typing messages and a button
         (id="send-button") to send them.
   * Styling and Scripting: Integrates Tailwind CSS for responsive and modern design, and links to script.js for interactive functionality.


  web/static/css/style.css
  This CSS file provides custom styling for the web interface, primarily using Tailwind CSS classes but also adding some specific rules.    
   * Custom Scrollbar: Defines styles for the scrollbar within the chat-container for a more modern look.
   * Message Bubbles:
       * .user-message: Styles for messages sent by the user (blue background, white text, rounded corners, aligned to the right).
       * .gemini-message: Styles for messages received from Gemini (darker gray background, light gray text, rounded corners, aligned to the
         left, uses pre-wrap and monospace for code-like formatting).
       * .message-bubble: Common styles for both user and Gemini messages (padding, margin, box shadow).
   * Loader: Defines CSS for a spinning loader animation (.loader, .loader-sm, .loader-xs) used to indicate processing.


  support/prompt-bank/meta.txt
  This file acts as a meta-prompt, providing overarching instructions for how the Gemini CLI should behave when simulating different interview
   roles.
   * Context: Explains that the user is a job candidate preparing for interviews and has created a PromptBank folder with seven prompt files, 
     each defining a specific interview simulation role.
   * Task: Instructs Gemini to sequentially read and process each of the seven prompt files. It emphasizes parsing the role, waiting for user 
     input, not executing all prompts at once, and strictly following constraints and output formats.
   * Start Trigger: Specifies the order in which the prompt files should be processed, starting with 01_JFA.txt, and the trigger phrase       
     ("Next Prompt") to move to the subsequent file.
   * Reminder: Reinforces that Gemini should act only as per the prompt instructions in the current file and not summarize, critique, or      
     modify them.


  support/prompt-bank/*.txt (e.g., 06_HR.txt, 05_Man.txt, 04_TPM.txt, 03_TL.txt, 03_PM.txt, 02_HM.txt, 01_JFA.txt)
  These files are individual prompt definitions, each outlining a specific interview simulation role for Gemini.
   * Structure: Each file follows a consistent structure:
       * `<Role>`: Defines the persona Gemini should adopt (e.g., "Human Resources Interviewer," "Managerial Interviewer," "Senior Technical 
         Product Manager Interviewer").
       * `<Context>`: Provides background information about the interview type and its importance.
       * `<Instructions>`: Details the steps Gemini should follow during the interview, including what information to ask from the user, the 
         types of questions to ask, how to provide feedback, and what to summarize at the end.
       * `<Constraints>`: Specifies limitations and rules for Gemini's behavior during the simulation (e.g., "Avoid technical, product, or   
         managerial questions" for HR).
       * `<Output_Format>`: Defines the exact structure and content for Gemini's responses during the interview, including feedback sections.
       * `<User_Input>`: Specifies what information Gemini should request from the user to start the simulation.
   * Functionality: When meta.txt instructs Gemini to process one of these files, Gemini adopts the defined role and follows the instructions
     to conduct a mock interview, providing structured feedback based on the specified output format.


  launch_gemini.bat
  This is a simple Windows batch script used to launch the Gemini CLI.
   * Command: @echo off suppresses command echoing. gemini --model gemini-2.5-flash --yolo 2>&1 executes the Gemini CLI with specific      
     parameters:
       * --model gemini-2.5-flash: Specifies the Gemini model to use.
       * --yolo: Likely a flag for "You Only Live Once," possibly indicating a non-interactive or single-session mode, or a specific output
         behavior.
       * 2>&1: Redirects standard error to standard output, ensuring all output (including errors) goes to the console.
   * Purpose: This script is called by app.py to start the Gemini CLI in a new console window, allowing the Flask application to interact  
     with it.


  web/static/js/script.js
  This JavaScript file handles the client-side interactivity of the web interface.
   * DOM Content Loaded Listener: Ensures the script runs after the HTML document is fully loaded.
   * Element Selection: Gets references to the form, input field, chat container, and send button.
   * Welcome Message Removal: Removes the initial "Welcome!" message from the chat container when the user first focuses on the input field.
   * Form Submission Handler:
       * Prevents default form submission.
       * Gets the user's prompt, trims it, and returns if empty.
       * Disables the input and send button, and shows a small loading spinner on the send button.
       * Immediately displays the user's message in the chat.
       * Adds a "Thinking..." placeholder for Gemini's response.
       * Sends the prompt to the Flask backend (/send_prompt) using fetch (an asynchronous HTTP request).
       * Upon receiving a response from the backend, it updates the "Thinking..." placeholder with Gemini's actual response.
       * Handles potential network or server errors.
       * Re-enables the input and send button, and focuses on the input field.
   * `addMessage` Function:
       * Creates a new div element for a message bubble.
       * Adds CSS classes based on the sender (user or gemini) for styling and alignment.
       * If isThinking is true, it displays a small loader and "Thinking...".
       * Otherwise, it wraps the message text in a <pre> tag (to preserve formatting like newlines and spaces) and adds it to the bubble.   
       * Appends the message bubble to the chat-container and scrolls to the bottom.
       * Returns the message bubble element, allowing it to be updated later.
   * `updateMessage` Function: Updates the content of an existing message bubble element with new text, also wrapped in <pre>, and scrolls  
     the chat to the bottom.
   * Dynamic Loader Styles: Appends a <style> tag to the document head to define CSS for the small loader animations used in the button and 
     thinking message.


  support/resume/Resume.md
  This Markdown file contains a sample resume.
   * Purpose: It's intended to be used as input for the interview simulation prompts (e.g., by the Job Fit Analyzer, Hiring Manager, or
     Technical Lead roles) to provide a realistic candidate profile.
   * Content: Includes sections like Professional Summary, Experience, Education, Skills, Projects, Certifications, and Volunteering,  
     formatted in Markdown.


  support/jds/Google.md
  This Markdown file contains a sample job description.
   * Purpose: Similar to Resume.md, this file serves as input for the interview simulation prompts, allowing Gemini to analyze job       
     requirements against the provided resume.
   * Content: Describes a "Product Manager, Artificial Intelligence â€“ Google AI" role, including sections like About the Job,
     Responsibilities, Minimum Qualifications, Preferred Qualifications, The Google AI Product Stack, and What We Offer, formatted in    
     Markdown.


  In summary, this project sets up a local web interface to interact with the Gemini CLI, allowing users to simulate various interview
  scenarios by feeding job descriptions and resumes to the AI, which then acts as different interviewers based on predefined prompts. The
  communication between the web frontend, Flask backend, and Gemini CLI is managed through file I/O and process control.